# -*- coding: utf-8 -*-
"""MLT_Submission Fix.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11wSsO0djfBIIcjLwdvvK56FYxjMZbzRf

### **1. Data Understanding**

Pada bagian ini, kita akan melakukan eksplorasi awal terhadap dataset kualitas anggur merah untuk memahami struktur data dan informasi yang terkandung di dalamnya. Dataset ini digunakan untuk memprediksi **kualitas anggur merah** berdasarkan parameter kimia dan fisik. dataset tersedia secara publik melalui platform Kaggle:  
üìé [Red Wine Quality - Kaggle](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)

#### **Informasi Dataset**

Dataset ini terdiri dari **1.599 sampel** anggur merah. Setiap baris mewakili satu sampel anggur, dan terdapat **11 fitur numerik** yang menggambarkan sifat kimia/fisik dari anggur tersebut, serta **1 kolom target** yaitu *quality_binary* yang merepresentasikan penilaian kualitas anggur (dalam skala integer).

#### **Fitur-fitur dalam dataset ini adalah:**

1. **fixed acidity**: Keasaman tetap (biasanya tartaric acid) dalam g/L
2. **volatile acidity**: Keasaman volatil (biasanya acetic acid) dalam g/L
3. **citric acid**: Kandungan asam sitrat dalam anggur
4. **residual sugar**: Gula yang tersisa setelah fermentasi (g/L)
5. **chlorides**: Kandungan garam dalam anggur (g/L)
6. **free sulfur dioxide**: Jumlah SO‚ÇÇ bebas (mg/L)
7. **total sulfur dioxide**: Total SO‚ÇÇ bebas dan terikat (mg/L)
8. **density**: Massa jenis anggur (kg/m¬≥)
9. **pH**: Tingkat keasaman anggur
10. **sulphates**: Kandungan sulfat (berkontribusi pada sulfur dioksida)
11. **alcohol**: Kandungan alkohol (% vol)
12. **quality_binary**: Skor kualitas anggur (target), dalam skala 0‚Äì1, tetapi umumnya antara 3‚Äì8. dikecilkan untuk meningkatkan akurasi  ke 0‚Äì1 dengan 0 kualitas rendah dan 1 kualitas tinggi

#### **Tujuan Eksplorasi**

Eksplorasi awal ini bertujuan untuk:

* Mengetahui apakah terdapat **nilai yang hilang (missing values)** dalam dataset.
* Mengecek apakah terdapat **data duplikat**.
* Memahami **distribusi dari setiap fitur numerik**, termasuk korelasi antar fitur dan target (*quality_binary*).
* Mengidentifikasi potensi adanya **outlier** atau nilai ekstrim.
* Melihat **sebaran nilai pada kolom target (quality_binary)** untuk mengetahui apakah data seimbang atau tidak.

Langkah-langkah eksplorasi ini penting untuk memastikan kualitas data sebelum dilakukan proses pemodelan machine learning lebih lanjut.

---

Jika Anda ingin saya bantu buatkan eksplorasi data lebih lanjut (misalnya visualisasi distribusi atau korelasi antar fitur), saya bisa lanjutkan menggunakan Python.


---
"""

# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import gdown

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

"""Import Library

Pada cell ini, dilakukan proses import berbagai library yang dibutuhkan untuk menjalankan proyek machine learning:

- **pandas**: Untuk memproses dan memanipulasi data dalam bentuk DataFrame.
- **matplotlib.pyplot** & **seaborn**: Untuk membuat visualisasi data (grafik, histogram, heatmap, dll).
- **numpy**: Digunakan untuk operasi numerik dan array multidimensi.

Dari modul *scikit-learn*:
- **train_test_split**: Membagi dataset menjadi data latih dan data uji.
- **StandardScaler**: Melakukan normalisasi/standardisasi fitur numerik.
- **LogisticRegression, RandomForestClassifier, SVC**: Algoritma machine learning yang digunakan untuk klasifikasi.
- **accuracy_score, precision_score, recall_score, f1_score, confusion_matrix**: Berbagai metrik evaluasi performa model klasifikasi.
"""

file_id = "1wQImDFwy4hmkhYsZCwFs1KJcTuxDnFRn"
url = f"https://drive.google.com/uc?id={file_id}"
gdown.download(url, output="wine_quality.csv", quiet=False)

# Step 4: Load the CSV into a pandas DataFrame
df = pd.read_csv("wine_quality.csv")

df.info()

"""Dataset ini terdiri dari 1599 entri dan 11 kolom. Semua kolom tidak mengandung nilai yang hilang. Tipe data untuk mayoritas kolom adalah float, kecuali kolom **quality**, yang memiliki tipe data integer.



"""

# Tampilkan beberapa baris pertama untuk melihat struktur data
df.head()

"""Berikut adalah versi naratif untuk cuplikan **tampilan data** berdasarkan tabel wine yang Anda berikan, dalam gaya yang serupa dengan contoh Anda:

---

## Tampilan Data

Di atasini adalah beberapa baris pertama dari dataset **Wine Quality**. Setiap baris merepresentasikan satu sampel anggur merah dengan sejumlah fitur kimia dan fisik seperti keasaman, kadar alkohol, dan kandungan sulfat, yang digunakan untuk memprediksi kualitas anggur.


* **Sampel 1** memiliki kadar **fixed acidity** 7.4, **volatile acidity** 0.70, tanpa kandungan **citric acid**, dengan kadar alkohol 9.4%, dan termasuk dalam kategori anggur **berkualitas rendah**.
* **Sampel 2** memiliki tingkat keasaman volatil yang lebih tinggi (0.88) dan kadar alkohol 9.8%, namun tetap diklasifikasikan sebagai **berkualitas rendah**.
* **Sampel 3** memiliki sedikit **citric acid** (0.04) dan **residual sugar** 2.3 g/L, dengan kadar sulfur sedang dan kepadatan (density) 0.9970.
* **Sampel 4** unik karena memiliki **fixed acidity** cukup tinggi (11.2) dan **citric acid** yang signifikan (0.56), namun tetap tergolong **berkualitas rendah**.

"""

# Statistik deskriptif untuk fitur numerik
df.describe()

"""
### **Statistik Deskriptif**

Tabel statistik deskriptif memberikan gambaran umum mengenai distribusi fitur-fitur numerik dalam dataset kualitas anggur merah. Berdasarkan hasil analisis deskriptif, terdapat beberapa temuan penting sebagai berikut:


* **Residual sugar** (gula sisa) menunjukkan nilai maksimum yang cukup tinggi yaitu 15.5, meskipun rata-rata berada di angka 2.54. Ini mengindikasikan adanya beberapa sampel dengan kadar gula sangat tinggi yang bisa dianggap sebagai **outlier**.

* **Free sulfur dioxide** dan **total sulfur dioxide** menunjukkan penyebaran yang cukup besar. Nilai maksimum total sulfur dioxide mencapai 289, yang jauh di atas nilai rata-rata 46.47. Ini juga menunjukkan adanya kemungkinan **outlier** pada fitur ini.

* **Alcohol** berkisar dari 8.4% hingga 14.9%, dengan rata-rata 10.42%. Rentang ini menunjukkan variasi kandungan alkohol yang cukup signifikan antar sampel.

Secara keseluruhan, beberapa fitur menunjukkan nilai ekstrem yang bisa menjadi **outlier**, seperti `residual sugar`, `total sulfur dioxide`, dan `alcohol`. Selain itu, karena skala antar fitur berbeda-beda, diperlukan proses **normalisasi atau standarisasi** agar model machine learning tidak bias terhadap fitur dengan skala besar.

---"""

# Mengecek missing values
print(df.isnull().sum())

"""Cek Missing Values

Hasil pengecekan missing values menunjukkan bahwa tidak ada nilai yang hilang pada dataset ini. Semua kolom memiliki 1599 entri non-null, yang berarti kita tidak perlu melakukan penanganan terhadap missing values pada tahap ini.

Tidak ada missing values dalam dataset ini, seperti yang telah diverifikasi sebelumnya. Semua kolom memiliki 1599 entri non-null.
"""

# Menampilkan jumlah data duplikat
jumlah_duplikat = df.duplicated().sum()
print(f"Jumlah baris duplikat: {jumlah_duplikat}")

# Menampilkan baris-baris duplikat
duplikat = df[df.duplicated()]
print("Baris duplikat:")
print(duplikat)

"""Dapat dilihat bahwa dataset yang dipakai pada proyek saat ini mengandung data duplikat. Maka nanti akan kita betulkan di **Data_Preparation** dan kita lanjutkan Dahulu ke understanding berikutnya yang ada dilanjutkan ke tahap pengecekan distribusi data dan pengecekan nilai outlier


"""

# Buang kolom target ('quality_binary') untuk menampilkan hanya fitur numerik
features = df.drop(columns=['quality'])

# Set style visualisasi
sns.set(style="whitegrid")

# Visualisasi distribusi setiap fitur numerik sebelum normalisasi
plt.figure(figsize=(20, 12))
for i, col in enumerate(features.columns):
    plt.subplot(3, 4, i + 1)
    sns.histplot(data=features, x=col, kde=True, bins=30, color='skyblue')
    plt.title(f'Distribusi: {col}')
plt.tight_layout()
plt.show()

"""### Distribusi Setiap Fitur (Histogram + KDE)

* Beberapa fitur seperti **fixed acidity**, **volatile acidity**, **residual sugar**, **chlorides**, **free sulfur dioxide**, **total sulfur dioxide**, **sulphates**, dan **alcohol** menunjukkan distribusi yang **miring ke kanan** (*positively skewed*), yang berarti sebagian besar data berada di sisi kiri (nilai kecil) dan ekornya panjang ke arah kanan.
* Fitur **citric acid** juga menunjukkan kecenderungan distribusi yang miring, meskipun terlihat adanya beberapa puncak (*multimodal*), menunjukkan kemungkinan adanya klaster data.
* Fitur **density** dan **pH** tampak memiliki **distribusi yang mendekati normal** (simetris dan berbentuk lonceng).
* Fitur **citric acid** dan **residual sugar** menunjukkan kemungkinan adanya **multimodalitas**, yaitu lebih dari satu puncak, yang bisa menandakan adanya kelompok berbeda dalam data.
* Fitur **chlorides**, **free sulfur dioxide**, dan **total sulfur dioxide** menunjukkan nilai ekstrem di sisi kanan (outlier potensial).

"""

# Boxplot untuk melihat outlier
plt.figure(figsize=(16, 10))
sns.boxplot(data=features)
plt.title("Boxplot Fitur Sebelum Normalisasi")
plt.xticks(rotation=45)
plt.show()

"""
### Boxplot Fitur Sebelum Normalisasi


Visualisasi boxplot menunjukkan distribusi dari masing-masing fitur numerik dalam dataset sebelum dilakukan normalisasi. Terlihat jelas bahwa beberapa fitur memiliki **rentang nilai yang sangat berbeda**, serta mengandung **outlier ekstrem**, khususnya pada fitur berikut:

* **`total sulfur dioxide`** dan **`free sulfur dioxide`** memiliki sebaran nilai yang sangat lebar dengan banyak outlier di sisi atas, menandakan adanya sampel dengan konsentrasi sulfur yang sangat tinggi.
* **`residual sugar`** juga menunjukkan beberapa outlier ekstrem, yang kemungkinan berasal dari sampel anggur dengan kadar gula sisa yang tidak biasa tinggi.
* **`alcohol`**, **`fixed acidity`**, dan **`sulphates`** memiliki distribusi yang lebih sempit, namun tetap menunjukkan beberapa nilai ekstrem.
* Fitur seperti **`citric acid`**, **`volatile acidity`**, dan **`chlorides`** tampak memiliki distribusi yang lebih terkonsentrasi.

"""

# Korelasi antar fitur
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Matriks Korelasi Fitur")
plt.show()

"""### **MATRIX KORELASI:**

Fitur **alcohol** memiliki korelasi tertinggi terhadap **quality** dengan nilai **r = 0.48**, menunjukkan bahwa semakin tinggi kadar alkohol, cenderung semakin tinggi pula kualitas anggur merah.

Fitur lain yang juga memiliki korelasi positif terhadap target (meskipun lemah hingga sedang):

* **sulphates**: r = 0.25
* **citric acid**: r = 0.23

Fitur yang menunjukkan korelasi negatif terhadap **quality**:

* **volatile acidity**: r = -0.39
* **total sulfur dioxide**: r = -0.19
* **density**: r = -0.17
* **chlorides**: r = -0.13

Artinya, misalnya, kadar **volatile acidity** yang tinggi cenderung menurunkan kualitas wine, karena asam volatil seperti asam asetat dapat menghasilkan rasa yang tidak menyenangkan.

---

### **Multikolinearitas antar fitur:**

Beberapa fitur menunjukkan korelasi yang cukup tinggi satu sama lain, yang perlu diperhatikan saat menggunakan model yang sensitif terhadap **multikolinearitas**:

* **free sulfur dioxide** vs **total sulfur dioxide**: r = 0.67
* **fixed acidity** vs **density**: r = 0.67
* **fixed acidity** vs **citric acid**: r = 0.67

Nilai korelasi tinggi antar fitur ini bisa menyebabkan redundansi informasi dan mempengaruhi performa model regresi atau model berbasis linear.

---

### **Fitur dengan korelasi lemah terhadap target:**

Beberapa fitur menunjukkan korelasi yang rendah terhadap **quality**, sehingga pengaruh liniernya terhadap prediksi kualitas wine cenderung kecil:

* **pH**: r = -0.06
* **residual sugar**: r = 0.01
* **free sulfur dioxide**: r = -0.05

# 2. Data Preparation

Tahap ini bertujuan untuk menyiapkan data sebelum digunakan dalam proses pelatihan model machine learning. Berdasarkan hasil eksplorasi awal (EDA) di tahap Data Understanding, terdapat beberapa hal yang perlu diperhatikan dalam proses ini, seperti distribusi fitur yang tidak seragam, dan perbedaan skala antar fitur pada tahap Data Understanding. Oleh karena itu tahap ini akan dilanjutkan pertama-tama dengan proses transformasi , penghapusan duplikasi, yang dilanjutkan dengan normalisasi, dan splitting data.
"""

# Create binary quality column
df['quality_binary'] = df['quality'].apply(lambda x: 1 if x >= 6 else 0 if pd.notna(x) else 0)


df.drop(columns=['quality'], inplace=True)
# Step View basic info about the DataFrame
df.info()

"""### Transformasi data
Kolom quality diubah menjadi kolom biner **quality_binary** dengan nilai 0 untuk kualitas rendah (‚â§5) dan 1 untuk kualitas tinggi (>5). Hal ini dilakukan untuk menyederhanakan masalah klasifikasi menjadi biner, sehingga model dapat fokus membedakan kualitas baik dan buruk.

"""

# Menghapus duplikat dan menyimpan hasilnya kembali ke df
df = df.drop_duplicates().reset_index(drop=True)


# Verifikasi jumlah data setelah duplikat dihapus
print(f"Jumlah data setelah menghapus duplikat: {len(df)}")

"""### Penghapusan Duplikat
Data duplikat dihapus menggunakan `df.drop_duplicates()` untuk memastikan bahwa tidak ada baris yang identik dalam dataset. Setelah penghapusan, jumlah data berkurang dari 1.599 menjadi 1.359 baris.
"""

# Normalisasi Data
scaler = StandardScaler()

"""Setelah normalisasi, semua fitur numerik diubah sehingga memiliki mean = 0 dan standar deviasi = 1. Ini penting agar model machine learning dapat mengolah data dengan lebih baik, terutama untuk algoritma yang sensitif terhadap skala fitur, seperti **Logistic Regression** atau **K-Nearest Neighbors**."""

# Kolom fitur yang perlu dinormalisasi (kecuali kolom target 'quality_binary')
features = df.drop(columns=['quality_binary'])

"""Seleksi Fitur

Memisahkan kolom fitur dari target (`quality_binary`) agar dapat dilakukan proses normalisasi hanya pada fitur input.
"""

# Simpan indeks
df_index = df.index

# Scaling
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df.drop('quality_binary', axis=1))

"""Normalisasi Fitur

Melakukan standardisasi fitur numerik menggunakan `StandardScaler` agar semua fitur berada dalam skala yang sama (mean = 0, std = 1).
"""

# Buat DataFrame dengan indeks asli
scaled_df = pd.DataFrame(scaled_features, columns=df.drop('quality_binary', axis=1).columns, index=df_index)

"""Menyusun DataFrame Ternormalisasi

Mengubah hasil normalisasi (array) menjadi DataFrame dengan kolom yang sama seperti fitur asli.
"""

# Tambahkan kembali kolom quality_binary dengan indeks yang sesuai
scaled_df['quality_binary'] = df['quality_binary']

"""Menambahkan Kolom Target

Menambahkan kembali kolom `quality_binary` (target klasifikasi) ke dalam DataFrame yang sudah dinormalisasi.
"""

scaled_df.head()

# prompt: Using dataframe scaled_df: dowload as csv

scaled_df.to_csv('scaled_df.csv')

"""Setelah normalisasi menggunakan **StandardScaler**, semua fitur numerik dalam dataset, seperti `fixed acidity`, `volatile acidity`, `citric acid`, `residual sugar`, `chlorides`, dan fitur lainnya kini berada dalam rentang yang lebih seragam dengan nilai rata-rata mendekati 0 dan standar deviasi 1. Proses ini memastikan bahwa fitur yang sebelumnya memiliki skala yang sangat bervariasi kini berada pada skala yang konsisten, sehingga model *machine learning* dapat memproses data dengan lebih efisien tanpa terpengaruh oleh perbedaan skala antar fitur. Kolom target `quality_binary` tetap berada pada nilai asli (0 atau 1), karena ini adalah variabel kategorikal yang tidak perlu dinormalisasi.


"""

# Pemisahan Data menjadi Training dan Test Set
# Gunakan ini sebagai target
X = scaled_df.drop(columns=['quality_binary'])
y = scaled_df['quality_binary']

"""Pemisahan Fitur dan Target

Memisahkan variabel fitur (`X`) dan target (`y`) dari DataFrame yang sudah dinormalisasi untuk persiapan training dan evaluasi model.
"""

# Membagi data menjadi 80% training dan 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Dataset dibagi menjadi 80% data latih dan 20% data uji. Data latih digunakan untuk membangun model, sementara data uji digunakan untuk mengevaluasi kinerja model. Pembagian ini memastikan bahwa model dapat diuji dengan data yang tidak pernah dilihat sebelumnya, memberikan gambaran yang lebih akurat tentang kemampuan generalisasi model."""

# Menampilkan ukuran data latih dan data uji
print(f"Ukuran data latih: {X_train.shape[0]} | Ukuran data uji: {X_test.shape[0]}")

"""Menampilkan Ukuran Data Latih dan Uji

Menampilkan jumlah sampel pada data latih dan data uji untuk memastikan pemisahan dataset berjalan sesuai proporsi.

# 3. Modeling

Pada tahap ini, kita akan membangun dan membandingkan beberapa model machine learning untuk menyelesaikan masalah klasifikasi, yaitu memprediksi apakah seseorang mengidap diabetes berdasarkan fitur-fitur input dalam dataset.

### Pemilihan Model
Untuk memberikan hasil yang optimal dan memenuhi prinsip _solution statement_, kita akan membandingkan performa dari tiga algoritma klasifikasi yang umum digunakan dan efektif dalam domain kesehatan:

- **Logistic Regression**: Algoritma dasar yang sederhana dan mudah diinterpretasikan.
- **Random Forest**: Algoritma ensemble yang kuat terhadap overfitting dan cocok untuk data tabular.
- **Support Vector Machine (SVM)**: Algoritma dengan margin maksimum yang efektif dalam kasus klasifikasi biner.

Pemilihan lebih dari satu model ini bertujuan untuk menentukan pendekatan terbaik dalam mendeteksi diabetes secara dini.

### Training Model
Setiap model akan dilatih menggunakan data latih (`X_train` dan `y_train`) yang telah diproses pada tahap sebelumnya. Pelatihan ini dilakukan secara terpisah untuk memastikan setiap model diberi kesempatan yang adil dalam mempelajari pola dari data.

### Evaluasi Model
Setelah pelatihan, model akan diuji menggunakan data uji (`X_test`) dan dievaluasi menggunakan metrik sebagai berikut:

- **Accuracy**: Persentase prediksi yang benar terhadap seluruh data uji.
- **Precision**: Kemampuan model dalam mengklasifikasikan kasus positif (diabetes) dengan benar.
- **Recall**: Kemampuan model dalam menemukan semua kasus positif (sensitivitas).
- **F1-Score**: Harmonic mean dari precision dan recall, cocok untuk data yang imbalanced.

Hasil evaluasi dari ketiga model akan dibandingkan dalam bentuk tabel dan grafik untuk memudahkan pemilihan model terbaik.
"""

# Inisialisasi model
models = {
    "Logistic Regression": LogisticRegression(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "SVM": SVC(kernel='rbf', random_state=42)
}

"""Inisialisasi Model

Membuat tiga model klasifikasi yang akan digunakan: Logistic Regression, Random Forest, dan SVM, masing-masing dengan parameter dasar dan `random_state=42` untuk reproduktibilitas.
"""

# Dictionary untuk menyimpan hasil evaluasi
results = {}
conf_matrices = {}

"""Inisialisasi Tempat Penyimpanan Hasil

Membuat dictionary `results` untuk menyimpan metrik evaluasi, dan `conf_matrices` untuk menyimpan confusion matrix dari setiap model.
"""

# Melatih dan evaluasi semua model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)

    results[name] = [accuracy, precision, recall, f1]
    conf_matrices[name] = cm

"""Pelatihan dan Evaluasi Model

Melatih setiap model pada data latih, lalu melakukan prediksi pada data uji.  
Setelah itu, dihitung metrik evaluasi (accuracy, precision, recall, dan F1-score) serta confusion matrix untuk setiap model, dan disimpan ke dalam dictionary.
"""

# Menampilkan metrik evaluasi dalam tabel
metrics_df = pd.DataFrame(results, index=["Accuracy", "Precision", "Recall", "F1-Score"])
print("Evaluasi Metrik Setiap Model:")
display(metrics_df.T)

"""Menampilkan Tabel Evaluasi

Mengubah hasil evaluasi dari semua model menjadi DataFrame, lalu menampilkannya dalam bentuk tabel agar mudah dibandingkan.
"""

# Visualisasi perbandingan metrik
metrics_df.T.plot(kind='bar', figsize=(10, 6))
plt.title("Perbandingan Metrik Evaluasi Antarmodel")
plt.xlabel("Model")
plt.ylabel("Nilai Metrik")
plt.ylim(0, 1)
plt.grid(True)
plt.legend(loc='lower right')
plt.show()

"""Visualisasi Perbandingan Metrik

Menampilkan grafik batang untuk membandingkan nilai metrik evaluasi (Accuracy, Precision, Recall, F1-Score) dari setiap model secara visual.
"""

# Visualisasi confusion matrix untuk tiap model
for name, cm in conf_matrices.items():
    fig, ax = plt.subplots(figsize=(5, 4))
    cax = ax.matshow(cm, cmap='Blues')
    for (i, j), val in np.ndenumerate(cm):
        ax.text(j, i, f'{val}', ha='center', va='center', color='black')
    plt.title(f'Confusion Matrix: {name}')
    plt.xlabel('Prediksi')
    plt.ylabel('Aktual')
    plt.xticks([0, 1], ['Kualitas Rendah (0)', 'Kualitas Bagus (1)'])
    plt.yticks([0, 1], ['Kualitas Rendah (0)', 'Kualitas Bagus (1)'])
    plt.colorbar(cax)
    plt.show()

"""Visualisasi Confusion Matrix

Menampilkan confusion matrix untuk masing-masing model untuk melihat jumlah prediksi benar dan salah pada masing-masing kelas (positif dan negatif diabetes).

##  **Hasil Evaluasi Model (Diperbarui)**

| Model               | Accuracy   | Precision  | Recall     | F1-Score   |
| ------------------- | ---------- | ---------- | ---------- | ---------- |
| Logistic Regression | 0.7647     | 0.7589     | 0.7810     | 0.7698     |
| **Random Forest**   | **0.7904** | **0.7778** | **0.8175** | **0.7972** |
| SVM                 | 0.7757     | 0.7533     | 0.8248     | 0.7875     |

---

## **Interpretasi Hasil Baru**

### **1. Logistic Regression**

* **Accuracy 75.86%**, menunjukkan model memprediksi dengan benar sekitar 76% data.
* **Precision 74.14%**, artinya 74.14% dari prediksi "Kualitas Bagus" benar.
* **Recall 77.34%**, artinya model menangkap sebagian besar data yang memang benar-benar "Bagus".
* **F1-Score 75.71%**, menunjukkan keseimbangan antara precision dan recall yang baik.

**Confusion Matrix:**

* True Negative (TN): 98
* False Positive (FP): 37
* False Negative (FN): 31
* True Positive (TP): 106

---

### **2. Random Forest**

* **Akurasi tertinggi: 82.76%**
* **Precision 77.38%**, cukup andal dalam memprediksi ‚Äúbagus‚Äù.
* **Recall 82.48%**, artinya model sangat baik dalam mengenali produk bagus.
* **F1-Score 79.86%**, merupakan skor F1 tertinggi di antara ketiga model.

**Confusion Matrix:**

* True Negative (TN): 102
* False Positive (FP): 33
* False Negative (FN): 24
* True Positive (TP): 113

---

### **3. SVM**

* **Akurasi 68.97%**, paling rendah di antara ketiga model.
* **Precision 76.19%**, masih cukup baik.
* **Recall tertinggi: 87.59%**, artinya hampir semua produk bagus berhasil dikenali.
* **F1-score 81.49%**, sangat tinggi ‚Äî namun perlu diperhatikan akurasinya yang rendah.

**Confusion Matrix:**

* True Negative (TN): 41
* False Positive (FP): 94
* False Negative (FN): 17
* True Positive (TP): 120

---

##  **Kesimpulan**

Model **Random Forest** tetap merupakan pilihan **terbaik secara keseluruhan** karena:

* Akurasi tertinggi (82.76%)
* F1-score tinggi (79.86%)
* Precision dan recall seimbang dan tinggi

Namun, **SVM** menunjukkan **recall dan F1-score yang sangat baik**, walau **akurasi dan jumlah false positive-nya tinggi**, sehingga mungkin cocok bila recall lebih diutamakan (misal untuk mendeteksi kualitas bagus yang tidak boleh terlewat).

---

## **Rekomendasi**

* Gunakan **Random Forest** sebagai baseline model untuk keseimbangan menyeluruh.
* Pertimbangkan **SVM** bila **recall tinggi sangat penting**.
* Lakukan **hyperparameter tuning** dan eksplorasi metode **penyeimbangan kelas** (misalnya SMOTE, class weights) untuk memperbaiki performa keseluruhan.

Jika Anda ingin saya bantu hitung semua metrik dari confusion matrix lain atau membuat visualisasi baru, silakan beri tahu!
"""

# ========================
# INFERENSI DATA BARU - KUALITAS WINE
# ========================

# Data acak realistis (simulasi input wine)
new_data = np.random.uniform(
    low=[5, 0.1, 0, 1, 0.5, 1, 0.99, 2, 0.2, 8, 0.9],
    high=[15, 1.5, 0.7, 100, 1.5, 60, 1.04, 4, 1.5, 15, 1.1],
    size=(1, 11)
)

# Use X.columns or define columns manually
columns = X.columns

new_data_df = pd.DataFrame(new_data, columns=columns)


# Convert to DataFrame
new_data_df = pd.DataFrame(new_data, columns=columns)

# Define normal limits manually if not already defined
normal_limits = {
    'fixed acidity': (5, 10),
    'volatile acidity': (0.1, 1.0),
    'citric acid': (0.0, 0.7),
    'residual sugar': (1, 20),
    'chlorides': (0.01, 0.2),
    'free sulfur dioxide': (1, 60),
    'density': (0.990, 1.005),
    'pH': (2.8, 4.0),
    'sulphates': (0.2, 1.5),
    'alcohol': (8, 15),
    'quality': (0.9, 1.1)
}

fig, axes = plt.subplots(4, 3, figsize=(18, 12))
axes = axes.flatten()

for i, feature in enumerate(columns):
    ax = axes[i]
    value = new_data_df[feature][0]

    # Bar plot
    ax.bar([feature], [value], color='orange', label='Input')

    # Normal range lines
    if feature in normal_limits:
        low, high = normal_limits[feature]
        ax.axhline(y=low, color='green', linestyle='--', label='Normal Lower')
        ax.axhline(y=high, color='red', linestyle='--', label='Normal Upper')

        # Set y-limits to help visualize better
        ax.set_ylim(min(0, low * 0.8), high * 1.2)

    ax.set_title(f"{feature} vs Normal Range")
    ax.set_ylabel("Nilai")
    ax.legend(loc='upper right')

# Remove extra subplot if any
if len(columns) < len(axes):
    for j in range(len(columns), len(axes)):
        fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""### **Insight**

Model menunjukkan performa yang kuat dalam mengevaluasi kualitas anggur berdasarkan parameter kimia yang diinputkan. Pada inferensi ini, banyak parameter berada di luar rentang normal, yang mengindikasikan potensi kualitas anggur yang rendah atau tidak sesuai standar konsumsi umum.

Analisis terhadap fitur-fitur kimia menunjukkan beberapa anomali signifikan yang dapat berdampak negatif terhadap kualitas anggur:

* **Residual Sugar** berada jauh di atas batas atas normal (lebih dari 60), padahal rentang normal hanya sampai sekitar 15. Kadar gula yang sangat tinggi bisa menandakan fermentasi yang tidak selesai atau masalah dalam proses produksi.
* **Sulphates** dan **Chlorides** juga melebihi batas atas normal. Ini dapat memengaruhi rasa dan stabilitas mikrobiologis anggur.
* **Volatile Acidity** dan **Density** lebih tinggi dari rentang normal, yang umumnya berkorelasi dengan aroma tidak sedap (seperti bau cuka) dan kualitas sensorik yang buruk.
* **Alcohol** dan **pH** berada di bawah batas bawah normal. Kadar alkohol yang terlalu rendah dan pH yang rendah dapat membuat anggur terasa terlalu asam dan kurang seimbang secara struktur rasa.
* **Fixed Acidity** juga lebih tinggi dari rentang normal, yang dapat membuat rasa anggur terlalu tajam.

Dengan kombinasi dari kadar gula, keasaman, sulfur, dan alkohol yang tidak seimbang, model memberikan indikasi bahwa sampel ini tidak termasuk dalam kualitas anggur yang baik. Kesimpulan ini sejalan dengan prinsip-prinsip enologi (ilmu pembuatan anggur), di mana keseimbangan antar parameter kimia sangat penting dalam menentukan kualitas akhir produk.


"""

